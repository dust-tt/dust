import { PythonSandbox } from "../sandbox";
import type { Tool, AnyTool } from "../tools/types";
import { generateToolDocs } from "./helpers";
import { z } from "zod";
import { defineTool } from "../tools/helpers";
import { systemPrompt, firstStepPrompt, continuePrompt, toolDocsPrompt, finalAnswerPrompt } from "./prompts";
import { logger } from "../utils/logger";
import { 
  ValidationError,
  APIError,
  SandboxError,
  wrapError
} from "../utils/errors";
import { LLMService } from "../services/llm";
import type { Message } from "../services/llm";
import { loadModelConfig } from "../utils/config";
import type { ModelConfig } from "../utils/config";

/**
 * Represents a single step in the agent's execution
 */
interface StepResult {
  /** The text generated by the agent */
  generation: string;
  /** The output from executing the generated code */
  codeOutput: string;
}

/**
 * An AI agent that generates and executes Python code to solve tasks
 */
export class Agent {
  /** The sandbox for executing Python code */
  private sandbox!: PythonSandbox;
  /** The LLM service for generating code */
  private llmService: LLMService;
  /** The model configuration */
  private modelConfig: ModelConfig;
  /** Set of tool names that have been exposed to the sandbox */
  private exposedTools: Set<string> = new Set();
  /** The goal the agent is trying to achieve */
  private goal: string;
  /** History of all steps taken by the agent */
  private steps: StepResult[] = [];
  /** Whether the agent should continue or return a final answer */
  private shouldContinue = true;

  private constructor(goal: string, modelConfig: ModelConfig) {
    this.goal = goal;
    this.modelConfig = modelConfig;
    this.llmService = new LLMService(modelConfig);
  }

  /**
   * Creates a special tool that allows the agent to stop execution and provide a final answer
   * @returns A Tool that signals the end of execution
   */
  private getFinalExecutionTool(): Tool<Record<string, never>, null> {
    return defineTool(
      "Must be used when the execution logs contain enough information to provide a final answer to the user." +
        "After using this function, the user will ask you to write a final answer based on your execution logs. " +
        "This function must be awaited like any other function.",
      z.object({}),
      z.null(),
      async () => {
        this.shouldContinue = false;
        return { type: "success", result: null };
      }
    );
  }

  static async create(goal: string): Promise<Agent> {
    logger.separator();
    logger.info(`Creating agent with goal: ${goal}`);
    logger.separator();
    
    // Load model configuration from environment variables
    const modelConfig = loadModelConfig();
    logger.info(`Using ${modelConfig.provider} with model: ${modelConfig.model}`);
    
    const agent = new Agent(goal, modelConfig);
    agent.sandbox = await PythonSandbox.create();
    return agent;
  }

  /**
   * Executes one step of the agent, generating and running Python code
   * @param _tools Dictionary of tools to make available to the agent
   * @returns The final answer if the agent decides to stop, or null if it needs to continue
   */
  async step(_tools: Record<string, AnyTool>): Promise<string | null> {
    const tools = { ..._tools };
    if (Object.keys(tools).some((name) => name === "stop_execution")) {
      throw new ValidationError("Reserved tool name cannot be used")
        .addContext({
          reservedToolName: "stop_execution",
          providedTools: Object.keys(tools)
        });
    }
    
    // Add stop_execution tool, converting to AnyTool for compatibility
    const stopTool = this.getFinalExecutionTool();
    tools["stop_execution"] = stopTool as unknown as AnyTool;

    // Expose or update tools
    const errors: Array<{ tool: string; error: string }> = [];
    const logs: Array<string> = [];
    
    for (const [name, tool] of Object.entries(tools)) {
      this.sandbox.expose<unknown, unknown>(name, {
        ...tool,
        fn: async (input: unknown) => {
          // Call the tool with the input and a logging context
          const result = await tool.fn(input, {
            log: (message: string) => {
              logs.push(message + "\n");
            },
          });
          
          // If successful, return the result
          if (result.type === "success") {
            return result.result;
          }
          
          // If there was an error, record it and return null
          errors.push({ tool: name, error: result.error });
          return null;
        },
      });
      
      // Keep track of which tools have been exposed
      this.exposedTools.add(name);
    }

    // Initialize messages with system and user prompts
    const messages: Message[] = [
      {
        role: "system",
        content: systemPrompt,
      },
      {
        role: "user",
        content: this.goal,
      },
    ];

    // Add messages for each previous step
    for (const step of this.steps) {
      // Add the assistant's response from the previous step
      messages.push({
        role: "assistant",
        content: step.generation,
      });
      
      // Add the user's response with the code output
      messages.push({
        role: "user",
        content: continuePrompt(step.codeOutput),
      });
    }

    // For the first step, add instructions to begin with analysis and code block
    if (!this.steps.length) {
      messages[messages.length - 1].content += firstStepPrompt;
    }

    // Add tool documentation to the last message
    messages[messages.length - 1].content += toolDocsPrompt(generateToolDocs(tools));

    logger.separator();
    logger.debug("Messages:");
    logger.debug(JSON.stringify(messages, null, 2));
    logger.separator();

    let llmResponse;
    try {
      llmResponse = await this.llmService.generateCompletion(messages);
    } catch (error) {
      // The LLMService already wraps the error, so we just rethrow it
      throw error;
    }

    // Extract code from the response
    const content = llmResponse.content;
    logger.separator();
    logger.info("Code generation response:");
    logger.info(content);
    logger.separator();

    const codeMatch = content.match(/```python\n([\s\S]*?)```/) ||
      content.match(/```\n([\s\S]*?)```/) || [null, content];
    const code = codeMatch[1].trim();

    // Execute the code
    // Execute the code with improved error handling
    const codeOutput = await (async () => {
      try {
        // Run the code in sandbox
        const codeOutput = await this.sandbox.runCode(code);
        
        // Format the outputs
        let output = "";
        if (codeOutput.stdout) {
          output += `STDOUT:\n${codeOutput.stdout}\n\n`;
        }
        if (logs.length > 0) {
          output += `EXECUTION LOGS:\n${logs.join("\n")}\n\n`;
        }
        if (codeOutput.stderr) {
          output += `STDERR:\n${codeOutput.stderr}\n\n`;
        }
        if (errors.length > 0) {
          output += `ERRORS:\n${errors
            .map((e) => `* ${e.tool}: ${e.error}`)
            .join("\n")}\n\n`;
        }

        if (!output) {
          return "No output returned from the code.";
        }

        return output;
      } catch (error) {
        // Log detailed error for debugging
        if (error instanceof SandboxError) {
          logger.debug("Sandbox execution failed with error:");
          logger.debug(`Message: ${error.message}`);
          logger.debug(`Context: ${JSON.stringify(error.context, null, 2)}`);
          logger.debug(`Stdout: ${error.stdout}`);
          logger.debug(`Stderr: ${error.stderr}`);
          
          // Return formatted error for the model
          return `STDERR:\n${error.stderr || error.message}`;
        } else {
          // For other errors, wrap them for consistent handling
          const wrappedError = wrapError(error, "Code execution failed");
          logger.debug(`Code execution error: ${wrappedError.message}`);
          
          // Return a user-friendly error message for the model
          return `STDERR:\n${wrappedError.message}`;
        }
      }
    })();

    logger.separator();
    logger.info("Code output:");
    logger.info(codeOutput);
    logger.separator();

    messages.push({
      role: "assistant",
      content: content,
    });

    if (!this.shouldContinue) {
      // Add the final answer prompt
      messages.push({
        role: "user",
        content: finalAnswerPrompt,
      });
      
      try {
        const finalResponse = await this.llmService.generateCompletion(messages);
        return finalResponse.content;
      } catch (error) {
        // Handle API errors in final response generation
        if (error instanceof APIError) {
          logger.logError(error.addContext({
            isFinalAnswer: true
          }));
        } else {
          logger.logError(wrapError(error, "Failed to generate final response"));
        }
        
        // Return a fallback response since this is the final step
        return "I was unable to generate a final response due to an API error. Please check the execution logs for the information gathered so far.";
      }
    }

    const stepResult: StepResult = {
      generation: content,
      codeOutput: codeOutput,
    };

    logger.separator();
    logger.debug("Step result:");
    logger.debug(JSON.stringify(stepResult, null, 2));
    logger.separator();

    this.steps.push(stepResult);

    return null;
  }

  /**
   * Gets the history of steps taken by the agent
   * @returns Array of step results containing generation and execution output
   */
  getSteps(): readonly StepResult[] {
    return [...this.steps];
  }
}

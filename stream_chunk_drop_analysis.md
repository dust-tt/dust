# Analysis of Dropped Events in Dust CLI Streaming

## Issue Description

The Dust CLI, a Node.js application using Ink for UI, occasionally drops chunks of the event stream when streaming agent responses. This document provides a comprehensive analysis of the issue, the system architecture, eliminated potential causes, and recommended areas for investigation.

## System Architecture Overview

### Components

1. **Dust CLI**: A Node.js terminal application using Ink (React for the terminal) to provide an interactive chat interface with Dust agents.

2. **Dust JavaScript SDK**: Interfaces with the Dust API to create conversations, post messages, and stream agent responses.

3. **Server-Sent Events (SSE)**: The streaming protocol used to deliver real-time events from the server to the client.

4. **Redis**: Used by the backend to publish events as they're generated by the agent.

5. **AgentMessageContentParser**: Server-side component that processes raw token events from the core system and classifies them (chain of thought, response, delimiter tags).

### Data Flow

1. User submits a message through the CLI
2. CLI creates a conversation or adds a message via the SDK
3. SDK connects to `/conversations/{conversationId}/messages/[messageId]/events` endpoint
4. Server subscribes to Redis channel for this conversation
5. Agent generates content, which is published as events to Redis
6. Server streams these events to the client using SSE
7. SDK parses the stream and yields events to the CLI
8. CLI renders the events in the terminal UI

## Issue Details

### Observed Patterns

1. **Stream chunks are occasionally dropped**, resulting in incomplete agent responses in the CLI.

2. **Consistent pattern to missing chunks**:

   - Almost always occur immediately after a "delimiter" event
   - Most commonly after the `<thinking>` tag (beginning of Chain of Thought)
   - Occasionally after the `<response>` tag (beginning of agent's response)

3. **Example scenario**:

   ```
   event1: "<thinking"
   event2: "> my cool thinking"
   ```

   event1 is buferred. Once event2 is received, the server emits:

   ```
   agentEvent1: {type: "delimiter", text: "<thinking>"}
   agentEvent2: {type: "tokens", classification: "chain_of_thought", text: "my cool thinking"}
   ```

   agentEvent2 is typically dropped (and has the same timestamp as agentEvent1)

4. **Location of the issue**:

   - Events are logged directly after `reader.read()` in the SDK
   - Chunks are missing in these logs, confirming it's not a UI rendering issue
   - Issue occurs before SSE parsing, indicating it's not an SSE parser issue

5. **Timing characteristics**:
   - Dropped event has the same "created" timestamp as the preceding delimiter event
   - In Redis, based on ID (insert timestamp), the dropped event appears ~3ms after the delimiter

### Eliminated Causes

1. ❌ **Not a CLI rendering issue**: Events are missing in raw SDK logs, before any rendering.

2. ❌ **Not an SSE parsing issue**: Events are missing in logs of raw stream chunks, before SSE parsing.

3. ❌ **Not an AgentMessageContentParser issue**: Tests show the parser correctly emits all events.

4. ❌ **Not a data loss in Redis**: All events, including dropped ones, are in Redis and can be retrieved later.

5. ❌ **Not a backpressure issue**: Events are processed quickly, and dropped events follow a specific pattern.

## Detailed Analysis

### Server-Side Events Emission

When processing agent outputs, the server-side `AgentMessageContentParser`:

1. Receives raw token events (e.g., `"<thinking"`, `">"`, `" my cool thinking"`)
2. Buffers these tokens until it can identify complete patterns
3. When it identifies a pattern, it emits multiple events at once
4. For delimiters, it often emits two consecutive events:
   - First: `{type: "delimiter", text: "<thinking>"}`
   - Second: `{type: "tokens", classification: "chain_of_thought", text: "my cool thinking"}`

These events have the same timestamp but appear in Redis with a slight delay (approximately 3ms).

### Streaming Implementation

The event streaming pipeline includes:

1. **Redis Publication**: Events are published to Redis as they're generated
2. **Server SSE Endpoint**: Subscribes to Redis and streams events to clients
3. **SDK Stream Processing**: Reads the stream and yields events to the CLI

Since all events are in Redis but some are dropped during streaming, the issue likely occurs either:

- In the server SSE endpoint's handling of Redis events
- In the network transport of SSE events
- In an edge case of the SSE protocol implementation

## Hypotheses

Based on analysis, the most likely causes are:

### 1. Server-Side Event Batching Issue

The server might be batching events that occur within the same millisecond but sometimes failing to send the complete batch. When events are generated in quick succession (as with delimiter + content), the second event might be lost.

### 2. SSE Transport Edge Case

The SSE protocol might have an edge case when handling multiple events generated at nearly the same time. If the server emits events too quickly, there might be a condition where events aren't properly delineated in the stream.

### 3. Redis → SSE Synchronization Issue

The process that consumes events from Redis and emits them as SSE might have a race condition. If multiple events arrive in Redis in quick succession, the consumer might miss events if it's not properly synchronizing its read position.

### 4. TCP Packet Boundary Issue

Since dropped events follow a consistent pattern, there might be an issue with how events are packaged into TCP packets. If events cross packet boundaries and the implementation doesn't handle packet reassembly correctly, events could be dropped.

## Next Steps for Investigation

### 1. Enhanced Logging

Implement comprehensive logging at critical points:

- Redis publication timestamps
- Server-side SSE emission timestamps
- Client-side receipt timestamps
- Add unique sequence IDs to events for tracking

### 2. Network Transport Analysis

- Perform packet capture during streaming to see if events are properly transmitted
- Analyze TCP packet boundaries to see if events might be split across packets
- Test with different network conditions to see if latency affects event dropping

### 3. Server-Side Component Testing

- Isolate the Redis → SSE bridge component for testing
- Implement a test that rapidly publishes events with the same pattern as observed
- Verify if all events make it through the pipeline

### 4. Implementation Modifications

- Modify the server to add sequence numbers to events
- Implement acknowledgment mechanisms for critical events
- Test alternative SSE library implementations

## Conclusion

The issue of dropped events in the Dust CLI stream is likely related to how events generated in rapid succession (particularly after delimiter tags) are handled in the streaming pipeline. The most probable area of concern is the server-side component that bridges Redis events to SSE streams, or potentially an edge case in the SSE protocol implementation itself.

Since the events are present in Redis but lost during streaming, focusing investigation on the server-side streaming implementation and the network transport layer will likely yield the most insight into this issue.

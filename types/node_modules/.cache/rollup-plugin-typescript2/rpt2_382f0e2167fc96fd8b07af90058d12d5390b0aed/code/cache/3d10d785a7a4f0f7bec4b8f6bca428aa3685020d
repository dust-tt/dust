{"code":"/**\n * Supported models\n */\nexport const GPT_4_TURBO_PREVIEW_MODEL_ID = \"gpt-4-turbo-preview\";\nexport const GPT_3_5_TURBO_MODEL_ID = \"gpt-3.5-turbo\";\nconst GPT_4_DESCRIPTION = \"OpenAI's most powerful and recent model (128k context).\";\nconst GPT_4_SHORT_DESCRIPTION = \"OpenAI's smartest model.\";\nexport const GPT_4_TURBO_MODEL_CONFIG = {\n    providerId: \"openai\",\n    modelId: GPT_4_TURBO_PREVIEW_MODEL_ID,\n    displayName: \"GPT 4\",\n    contextSize: 128_000,\n    recommendedTopK: 32,\n    largeModel: true,\n    description: GPT_4_DESCRIPTION,\n    shortDescription: GPT_4_SHORT_DESCRIPTION,\n};\nexport const GPT_3_5_TURBO_MODEL_CONFIG = {\n    providerId: \"openai\",\n    modelId: GPT_3_5_TURBO_MODEL_ID,\n    displayName: \"GPT 3.5 Turbo\",\n    contextSize: 16_384,\n    recommendedTopK: 16,\n    largeModel: false,\n    description: \"OpenAI's cost-effective and high throughput model (16k context).\",\n    shortDescription: \"OpenAI's fast model.\",\n};\nexport const CLAUDE_3_OPUS_2024029_MODEL_ID = \"claude-3-opus-20240229\";\nexport const CLAUDE_3_SONNET_2024029_MODEL_ID = \"claude-3-sonnet-20240229\";\nexport const CLAUDE_3_HAIKU_20240307_MODEL_ID = \"claude-3-haiku-20240307\";\nexport const CLAUDE_2_1_MODEL_ID = \"claude-2.1\";\nexport const CLAUDE_INSTANT_1_2_MODEL_ID = \"claude-instant-1.2\";\nexport const CLAUDE_3_OPUS_DEFAULT_MODEL_CONFIG = {\n    providerId: \"anthropic\",\n    modelId: CLAUDE_3_OPUS_2024029_MODEL_ID,\n    displayName: \"Claude 3 Opus\",\n    contextSize: 180_000,\n    recommendedTopK: 32,\n    largeModel: true,\n    description: \"Anthropic's Claude 3 Opus model, most powerful model for highly complex tasks.\",\n    shortDescription: \"Anthropic's powerful model.\",\n};\nexport const CLAUDE_3_SONNET_DEFAULT_MODEL_CONFIG = {\n    providerId: \"anthropic\",\n    modelId: CLAUDE_3_SONNET_2024029_MODEL_ID,\n    displayName: \"Claude 3 Sonnet\",\n    contextSize: 180_000,\n    recommendedTopK: 32,\n    largeModel: true,\n    description: \"Anthropic Claude 3 Sonnet model, targeting balance between intelligence and speed for enterprise workloads.\",\n    shortDescription: \"Anthropic's balanced model.\",\n};\nexport const CLAUDE_3_HAIKU_DEFAULT_MODEL_CONFIG = {\n    providerId: \"anthropic\",\n    modelId: CLAUDE_3_HAIKU_20240307_MODEL_ID,\n    displayName: \"Claude 3 Haiku\",\n    contextSize: 180_000,\n    recommendedTopK: 32,\n    largeModel: true,\n    description: \"Anthropic Claude 3 Haiku model, fastest and most compact model for near-instant responsiveness.\",\n    shortDescription: \"Anthropic's quick model.\",\n};\nexport const CLAUDE_2_DEFAULT_MODEL_CONFIG = {\n    providerId: \"anthropic\",\n    modelId: CLAUDE_2_1_MODEL_ID,\n    displayName: \"Claude 2.1\",\n    contextSize: 180_000,\n    recommendedTopK: 32,\n    largeModel: true,\n    description: \"Anthropic's Claude 2 model (200k context).\",\n    shortDescription: \"Anthropic's smartest model.\",\n};\nexport const CLAUDE_INSTANT_DEFAULT_MODEL_CONFIG = {\n    providerId: \"anthropic\",\n    modelId: CLAUDE_INSTANT_1_2_MODEL_ID,\n    displayName: \"Claude Instant 1.2\",\n    contextSize: 90_000,\n    recommendedTopK: 32,\n    largeModel: false,\n    description: \"Anthropic's low-latency and high throughput model (100k context)\",\n    shortDescription: \"Anthropic's fast model.\",\n};\nexport const MISTRAL_LARGE_MODEL_ID = \"mistral-large-latest\";\nexport const MISTRAL_MEDIUM_MODEL_ID = \"mistral-medium\";\nexport const MISTRAL_SMALL_MODEL_ID = \"mistral-small\";\nexport const MISTRAL_LARGE_MODEL_CONFIG = {\n    providerId: \"mistral\",\n    modelId: MISTRAL_LARGE_MODEL_ID,\n    displayName: \"Mistral Large\",\n    contextSize: 32_000,\n    recommendedTopK: 16,\n    largeModel: true,\n    description: \"Mistral's latest `large` model (32k context).\",\n    shortDescription: \"Mistral's large model.\",\n};\nexport const MISTRAL_MEDIUM_MODEL_CONFIG = {\n    providerId: \"mistral\",\n    modelId: MISTRAL_MEDIUM_MODEL_ID,\n    displayName: \"Mistral Medium\",\n    contextSize: 32_000,\n    recommendedTopK: 16,\n    largeModel: true,\n    description: \"Mistral's latest `medium` model (32k context).\",\n    shortDescription: \"Mistral's smartest model.\",\n};\nexport const MISTRAL_SMALL_MODEL_CONFIG = {\n    providerId: \"mistral\",\n    modelId: MISTRAL_SMALL_MODEL_ID,\n    displayName: \"Mistral Small\",\n    contextSize: 32_000,\n    recommendedTopK: 16,\n    largeModel: false,\n    description: \"Mistral's latest model (8x7B Instruct, 32k context).\",\n    shortDescription: \"Mistral's fast model.\",\n};\nconst GEMINI_1_5_PRO_LATEST_MODEL_ID = \"gemini-1.5-pro-latest\";\nexport const GEMINI_PRO_DEFAULT_MODEL_CONFIG = {\n    providerId: \"google_ai_studio\",\n    modelId: GEMINI_1_5_PRO_LATEST_MODEL_ID,\n    displayName: \"Gemini Pro 1.5\",\n    contextSize: 1_000_000,\n    recommendedTopK: 64,\n    largeModel: true,\n    description: \"Google's best model for scaling across a wide range of tasks (1M context).\",\n    shortDescription: \"Google's smartest model.\",\n};\nexport const SUPPORTED_MODEL_CONFIGS = [\n    GPT_3_5_TURBO_MODEL_CONFIG,\n    GPT_4_TURBO_MODEL_CONFIG,\n    CLAUDE_3_OPUS_DEFAULT_MODEL_CONFIG,\n    CLAUDE_3_SONNET_DEFAULT_MODEL_CONFIG,\n    CLAUDE_3_HAIKU_DEFAULT_MODEL_CONFIG,\n    CLAUDE_2_DEFAULT_MODEL_CONFIG,\n    CLAUDE_INSTANT_DEFAULT_MODEL_CONFIG,\n    MISTRAL_LARGE_MODEL_CONFIG,\n    MISTRAL_MEDIUM_MODEL_CONFIG,\n    MISTRAL_SMALL_MODEL_CONFIG,\n    GEMINI_PRO_DEFAULT_MODEL_CONFIG,\n];\nexport function isSupportedModel(model) {\n    const maybeSupportedModel = model;\n    return SUPPORTED_MODEL_CONFIGS.some((m) => m.modelId === maybeSupportedModel.modelId &&\n        m.providerId === maybeSupportedModel.providerId);\n}\n//# sourceMappingURL=assistant.js.map","references":["/Users/edouardwautier/Projects/dust/types/src/shared/typescipt_utils.ts"],"map":"{\"version\":3,\"file\":\"assistant.js\",\"sourceRoot\":\"\",\"sources\":[\"../../../../../../src/front/lib/assistant.ts\"],\"names\":[],\"mappings\":\"AAAA;;GAEG;AAIH,MAAM,CAAC,MAAM,4BAA4B,GAAG,qBAA8B,CAAC;AAC3E,MAAM,CAAC,MAAM,sBAAsB,GAAG,eAAwB,CAAC;AAE/D,MAAM,iBAAiB,GACrB,yDAAyD,CAAC;AAC5D,MAAM,uBAAuB,GAAG,0BAA0B,CAAC;AAE3D,MAAM,CAAC,MAAM,wBAAwB,GAAG;IACtC,UAAU,EAAE,QAAiB;IAC7B,OAAO,EAAE,4BAA4B;IACrC,WAAW,EAAE,OAAO;IACpB,WAAW,EAAE,OAAO;IACpB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EAAE,iBAAiB;IAC9B,gBAAgB,EAAE,uBAAuB;CACjC,CAAC;AAEX,MAAM,CAAC,MAAM,0BAA0B,GAAG;IACxC,UAAU,EAAE,QAAiB;IAC7B,OAAO,EAAE,sBAAsB;IAC/B,WAAW,EAAE,eAAe;IAC5B,WAAW,EAAE,MAAM;IACnB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,KAAK;IACjB,WAAW,EACT,kEAAkE;IACpE,gBAAgB,EAAE,sBAAsB;CAChC,CAAC;AAEX,MAAM,CAAC,MAAM,8BAA8B,GAAG,wBAAiC,CAAC;AAChF,MAAM,CAAC,MAAM,gCAAgC,GAC3C,0BAAmC,CAAC;AACtC,MAAM,CAAC,MAAM,gCAAgC,GAC3C,yBAAkC,CAAC;AACrC,MAAM,CAAC,MAAM,mBAAmB,GAAG,YAAqB,CAAC;AACzD,MAAM,CAAC,MAAM,2BAA2B,GAAG,oBAA6B,CAAC;AAEzE,MAAM,CAAC,MAAM,kCAAkC,GAAG;IAChD,UAAU,EAAE,WAAoB;IAChC,OAAO,EAAE,8BAA8B;IACvC,WAAW,EAAE,eAAe;IAC5B,WAAW,EAAE,OAAO;IACpB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EACT,gFAAgF;IAClF,gBAAgB,EAAE,6BAA6B;CACvC,CAAC;AAEX,MAAM,CAAC,MAAM,oCAAoC,GAAG;IAClD,UAAU,EAAE,WAAoB;IAChC,OAAO,EAAE,gCAAgC;IACzC,WAAW,EAAE,iBAAiB;IAC9B,WAAW,EAAE,OAAO;IACpB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EACT,6GAA6G;IAC/G,gBAAgB,EAAE,6BAA6B;CACvC,CAAC;AAEX,MAAM,CAAC,MAAM,mCAAmC,GAAG;IACjD,UAAU,EAAE,WAAoB;IAChC,OAAO,EAAE,gCAAgC;IACzC,WAAW,EAAE,gBAAgB;IAC7B,WAAW,EAAE,OAAO;IACpB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EACT,iGAAiG;IACnG,gBAAgB,EAAE,0BAA0B;CACpC,CAAC;AAEX,MAAM,CAAC,MAAM,6BAA6B,GAAG;IAC3C,UAAU,EAAE,WAAoB;IAChC,OAAO,EAAE,mBAAmB;IAC5B,WAAW,EAAE,YAAY;IACzB,WAAW,EAAE,OAAO;IACpB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EAAE,4CAA4C;IACzD,gBAAgB,EAAE,6BAA6B;CACvC,CAAC;AAEX,MAAM,CAAC,MAAM,mCAAmC,GAAG;IACjD,UAAU,EAAE,WAAoB;IAChC,OAAO,EAAE,2BAA2B;IACpC,WAAW,EAAE,oBAAoB;IACjC,WAAW,EAAE,MAAM;IACnB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,KAAK;IACjB,WAAW,EACT,kEAAkE;IACpE,gBAAgB,EAAE,yBAAyB;CACnC,CAAC;AAEX,MAAM,CAAC,MAAM,sBAAsB,GAAG,sBAA+B,CAAC;AACtE,MAAM,CAAC,MAAM,uBAAuB,GAAG,gBAAyB,CAAC;AACjE,MAAM,CAAC,MAAM,sBAAsB,GAAG,eAAwB,CAAC;AAE/D,MAAM,CAAC,MAAM,0BAA0B,GAAG;IACxC,UAAU,EAAE,SAAkB;IAC9B,OAAO,EAAE,sBAAsB;IAC/B,WAAW,EAAE,eAAe;IAC5B,WAAW,EAAE,MAAM;IACnB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EAAE,+CAA+C;IAC5D,gBAAgB,EAAE,wBAAwB;CAClC,CAAC;AAEX,MAAM,CAAC,MAAM,2BAA2B,GAAG;IACzC,UAAU,EAAE,SAAkB;IAC9B,OAAO,EAAE,uBAAuB;IAChC,WAAW,EAAE,gBAAgB;IAC7B,WAAW,EAAE,MAAM;IACnB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EAAE,gDAAgD;IAC7D,gBAAgB,EAAE,2BAA2B;CACrC,CAAC;AAEX,MAAM,CAAC,MAAM,0BAA0B,GAAG;IACxC,UAAU,EAAE,SAAkB;IAC9B,OAAO,EAAE,sBAAsB;IAC/B,WAAW,EAAE,eAAe;IAC5B,WAAW,EAAE,MAAM;IACnB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,KAAK;IACjB,WAAW,EAAE,sDAAsD;IACnE,gBAAgB,EAAE,uBAAuB;CACjC,CAAC;AAEX,MAAM,8BAA8B,GAAG,uBAAgC,CAAC;AAExE,MAAM,CAAC,MAAM,+BAA+B,GAAG;IAC7C,UAAU,EAAE,kBAA2B;IACvC,OAAO,EAAE,8BAA8B;IACvC,WAAW,EAAE,gBAAgB;IAC7B,WAAW,EAAE,SAAS;IACtB,eAAe,EAAE,EAAE;IACnB,UAAU,EAAE,IAAI;IAChB,WAAW,EACT,4EAA4E;IAC9E,gBAAgB,EAAE,0BAA0B;CACpC,CAAC;AAEX,MAAM,CAAC,MAAM,uBAAuB,GAAG;IACrC,0BAA0B;IAC1B,wBAAwB;IACxB,kCAAkC;IAClC,oCAAoC;IACpC,mCAAmC;IACnC,6BAA6B;IAC7B,mCAAmC;IACnC,0BAA0B;IAC1B,2BAA2B;IAC3B,0BAA0B;IAC1B,+BAA+B;CACvB,CAAC;AAWX,MAAM,UAAU,gBAAgB,CAAC,KAAc;IAC7C,MAAM,mBAAmB,GAAG,KAAuB,CAAC;IACpD,OAAO,uBAAuB,CAAC,IAAI,CACjC,CAAC,CAAC,EAAE,EAAE,CACJ,CAAC,CAAC,OAAO,KAAK,mBAAmB,CAAC,OAAO;QACzC,CAAC,CAAC,UAAU,KAAK,mBAAmB,CAAC,UAAU,CAClD,CAAC;AACJ,CAAC\"}","dtsmap":{"name":"/Users/edouardwautier/Projects/dust/types/node_modules/.cache/rollup-plugin-typescript2/placeholder/front/lib/assistant.d.ts.map","writeByteOrderMark":false,"text":"{\"version\":3,\"file\":\"assistant.d.ts\",\"sourceRoot\":\"\",\"sources\":[\"../../../../../../src/front/lib/assistant.ts\"],\"names\":[],\"mappings\":\"AAAA;;GAEG;AAEH,OAAO,EAAE,mBAAmB,EAAE,MAAM,8BAA8B,CAAC;AAEnE,eAAO,MAAM,4BAA4B,uBAAiC,CAAC;AAC3E,eAAO,MAAM,sBAAsB,iBAA2B,CAAC;AAM/D,eAAO,MAAM,wBAAwB;;;;;;;;;CAS3B,CAAC;AAEX,eAAO,MAAM,0BAA0B;;;;;;;;;CAU7B,CAAC;AAEX,eAAO,MAAM,8BAA8B,0BAAoC,CAAC;AAChF,eAAO,MAAM,gCAAgC,4BACR,CAAC;AACtC,eAAO,MAAM,gCAAgC,2BACT,CAAC;AACrC,eAAO,MAAM,mBAAmB,cAAwB,CAAC;AACzD,eAAO,MAAM,2BAA2B,sBAAgC,CAAC;AAEzE,eAAO,MAAM,kCAAkC;;;;;;;;;CAUrC,CAAC;AAEX,eAAO,MAAM,oCAAoC;;;;;;;;;CAUvC,CAAC;AAEX,eAAO,MAAM,mCAAmC;;;;;;;;;CAUtC,CAAC;AAEX,eAAO,MAAM,6BAA6B;;;;;;;;;CAShC,CAAC;AAEX,eAAO,MAAM,mCAAmC;;;;;;;;;CAUtC,CAAC;AAEX,eAAO,MAAM,sBAAsB,wBAAkC,CAAC;AACtE,eAAO,MAAM,uBAAuB,kBAA4B,CAAC;AACjE,eAAO,MAAM,sBAAsB,iBAA2B,CAAC;AAE/D,eAAO,MAAM,0BAA0B;;;;;;;;;CAS7B,CAAC;AAEX,eAAO,MAAM,2BAA2B;;;;;;;;;CAS9B,CAAC;AAEX,eAAO,MAAM,0BAA0B;;;;;;;;;CAS7B,CAAC;AAIX,eAAO,MAAM,+BAA+B;;;;;;;;;CAUlC,CAAC;AAEX,eAAO,MAAM,uBAAuB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAY1B,CAAC;AAEX,MAAM,MAAM,WAAW,GAAG,CAAC,OAAO,uBAAuB,CAAC,CAAC,MAAM,CAAC,CAAC;AAInE,MAAM,MAAM,cAAc,GAAG,mBAAmB,CAC9C,CAAC,OAAO,uBAAuB,CAAC,CAAC,MAAM,CAAC,EACxC,YAAY,GAAG,SAAS,CACzB,CAAC;AAEF,wBAAgB,gBAAgB,CAAC,KAAK,EAAE,OAAO,GAAG,KAAK,IAAI,cAAc,CAOxE\"}"},"dts":{"name":"/Users/edouardwautier/Projects/dust/types/node_modules/.cache/rollup-plugin-typescript2/placeholder/front/lib/assistant.d.ts","writeByteOrderMark":false,"text":"/**\n * Supported models\n */\nimport { ExtractSpecificKeys } from \"../../shared/typescipt_utils\";\nexport declare const GPT_4_TURBO_PREVIEW_MODEL_ID: \"gpt-4-turbo-preview\";\nexport declare const GPT_3_5_TURBO_MODEL_ID: \"gpt-3.5-turbo\";\nexport declare const GPT_4_TURBO_MODEL_CONFIG: {\n    readonly providerId: \"openai\";\n    readonly modelId: \"gpt-4-turbo-preview\";\n    readonly displayName: \"GPT 4\";\n    readonly contextSize: 128000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"OpenAI's most powerful and recent model (128k context).\";\n    readonly shortDescription: \"OpenAI's smartest model.\";\n};\nexport declare const GPT_3_5_TURBO_MODEL_CONFIG: {\n    readonly providerId: \"openai\";\n    readonly modelId: \"gpt-3.5-turbo\";\n    readonly displayName: \"GPT 3.5 Turbo\";\n    readonly contextSize: 16384;\n    readonly recommendedTopK: 16;\n    readonly largeModel: false;\n    readonly description: \"OpenAI's cost-effective and high throughput model (16k context).\";\n    readonly shortDescription: \"OpenAI's fast model.\";\n};\nexport declare const CLAUDE_3_OPUS_2024029_MODEL_ID: \"claude-3-opus-20240229\";\nexport declare const CLAUDE_3_SONNET_2024029_MODEL_ID: \"claude-3-sonnet-20240229\";\nexport declare const CLAUDE_3_HAIKU_20240307_MODEL_ID: \"claude-3-haiku-20240307\";\nexport declare const CLAUDE_2_1_MODEL_ID: \"claude-2.1\";\nexport declare const CLAUDE_INSTANT_1_2_MODEL_ID: \"claude-instant-1.2\";\nexport declare const CLAUDE_3_OPUS_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-opus-20240229\";\n    readonly displayName: \"Claude 3 Opus\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic's Claude 3 Opus model, most powerful model for highly complex tasks.\";\n    readonly shortDescription: \"Anthropic's powerful model.\";\n};\nexport declare const CLAUDE_3_SONNET_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-sonnet-20240229\";\n    readonly displayName: \"Claude 3 Sonnet\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic Claude 3 Sonnet model, targeting balance between intelligence and speed for enterprise workloads.\";\n    readonly shortDescription: \"Anthropic's balanced model.\";\n};\nexport declare const CLAUDE_3_HAIKU_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-haiku-20240307\";\n    readonly displayName: \"Claude 3 Haiku\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic Claude 3 Haiku model, fastest and most compact model for near-instant responsiveness.\";\n    readonly shortDescription: \"Anthropic's quick model.\";\n};\nexport declare const CLAUDE_2_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-2.1\";\n    readonly displayName: \"Claude 2.1\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic's Claude 2 model (200k context).\";\n    readonly shortDescription: \"Anthropic's smartest model.\";\n};\nexport declare const CLAUDE_INSTANT_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-instant-1.2\";\n    readonly displayName: \"Claude Instant 1.2\";\n    readonly contextSize: 90000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: false;\n    readonly description: \"Anthropic's low-latency and high throughput model (100k context)\";\n    readonly shortDescription: \"Anthropic's fast model.\";\n};\nexport declare const MISTRAL_LARGE_MODEL_ID: \"mistral-large-latest\";\nexport declare const MISTRAL_MEDIUM_MODEL_ID: \"mistral-medium\";\nexport declare const MISTRAL_SMALL_MODEL_ID: \"mistral-small\";\nexport declare const MISTRAL_LARGE_MODEL_CONFIG: {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-large-latest\";\n    readonly displayName: \"Mistral Large\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: true;\n    readonly description: \"Mistral's latest `large` model (32k context).\";\n    readonly shortDescription: \"Mistral's large model.\";\n};\nexport declare const MISTRAL_MEDIUM_MODEL_CONFIG: {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-medium\";\n    readonly displayName: \"Mistral Medium\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: true;\n    readonly description: \"Mistral's latest `medium` model (32k context).\";\n    readonly shortDescription: \"Mistral's smartest model.\";\n};\nexport declare const MISTRAL_SMALL_MODEL_CONFIG: {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-small\";\n    readonly displayName: \"Mistral Small\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: false;\n    readonly description: \"Mistral's latest model (8x7B Instruct, 32k context).\";\n    readonly shortDescription: \"Mistral's fast model.\";\n};\nexport declare const GEMINI_PRO_DEFAULT_MODEL_CONFIG: {\n    readonly providerId: \"google_ai_studio\";\n    readonly modelId: \"gemini-1.5-pro-latest\";\n    readonly displayName: \"Gemini Pro 1.5\";\n    readonly contextSize: 1000000;\n    readonly recommendedTopK: 64;\n    readonly largeModel: true;\n    readonly description: \"Google's best model for scaling across a wide range of tasks (1M context).\";\n    readonly shortDescription: \"Google's smartest model.\";\n};\nexport declare const SUPPORTED_MODEL_CONFIGS: readonly [{\n    readonly providerId: \"openai\";\n    readonly modelId: \"gpt-3.5-turbo\";\n    readonly displayName: \"GPT 3.5 Turbo\";\n    readonly contextSize: 16384;\n    readonly recommendedTopK: 16;\n    readonly largeModel: false;\n    readonly description: \"OpenAI's cost-effective and high throughput model (16k context).\";\n    readonly shortDescription: \"OpenAI's fast model.\";\n}, {\n    readonly providerId: \"openai\";\n    readonly modelId: \"gpt-4-turbo-preview\";\n    readonly displayName: \"GPT 4\";\n    readonly contextSize: 128000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"OpenAI's most powerful and recent model (128k context).\";\n    readonly shortDescription: \"OpenAI's smartest model.\";\n}, {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-opus-20240229\";\n    readonly displayName: \"Claude 3 Opus\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic's Claude 3 Opus model, most powerful model for highly complex tasks.\";\n    readonly shortDescription: \"Anthropic's powerful model.\";\n}, {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-sonnet-20240229\";\n    readonly displayName: \"Claude 3 Sonnet\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic Claude 3 Sonnet model, targeting balance between intelligence and speed for enterprise workloads.\";\n    readonly shortDescription: \"Anthropic's balanced model.\";\n}, {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-3-haiku-20240307\";\n    readonly displayName: \"Claude 3 Haiku\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic Claude 3 Haiku model, fastest and most compact model for near-instant responsiveness.\";\n    readonly shortDescription: \"Anthropic's quick model.\";\n}, {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-2.1\";\n    readonly displayName: \"Claude 2.1\";\n    readonly contextSize: 180000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: true;\n    readonly description: \"Anthropic's Claude 2 model (200k context).\";\n    readonly shortDescription: \"Anthropic's smartest model.\";\n}, {\n    readonly providerId: \"anthropic\";\n    readonly modelId: \"claude-instant-1.2\";\n    readonly displayName: \"Claude Instant 1.2\";\n    readonly contextSize: 90000;\n    readonly recommendedTopK: 32;\n    readonly largeModel: false;\n    readonly description: \"Anthropic's low-latency and high throughput model (100k context)\";\n    readonly shortDescription: \"Anthropic's fast model.\";\n}, {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-large-latest\";\n    readonly displayName: \"Mistral Large\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: true;\n    readonly description: \"Mistral's latest `large` model (32k context).\";\n    readonly shortDescription: \"Mistral's large model.\";\n}, {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-medium\";\n    readonly displayName: \"Mistral Medium\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: true;\n    readonly description: \"Mistral's latest `medium` model (32k context).\";\n    readonly shortDescription: \"Mistral's smartest model.\";\n}, {\n    readonly providerId: \"mistral\";\n    readonly modelId: \"mistral-small\";\n    readonly displayName: \"Mistral Small\";\n    readonly contextSize: 32000;\n    readonly recommendedTopK: 16;\n    readonly largeModel: false;\n    readonly description: \"Mistral's latest model (8x7B Instruct, 32k context).\";\n    readonly shortDescription: \"Mistral's fast model.\";\n}, {\n    readonly providerId: \"google_ai_studio\";\n    readonly modelId: \"gemini-1.5-pro-latest\";\n    readonly displayName: \"Gemini Pro 1.5\";\n    readonly contextSize: 1000000;\n    readonly recommendedTopK: 64;\n    readonly largeModel: true;\n    readonly description: \"Google's best model for scaling across a wide range of tasks (1M context).\";\n    readonly shortDescription: \"Google's smartest model.\";\n}];\nexport type ModelConfig = (typeof SUPPORTED_MODEL_CONFIGS)[number];\nexport type SupportedModel = ExtractSpecificKeys<(typeof SUPPORTED_MODEL_CONFIGS)[number], \"providerId\" | \"modelId\">;\nexport declare function isSupportedModel(model: unknown): model is SupportedModel;\n//# sourceMappingURL=assistant.d.ts.map"}}

import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## A first version of our Product Constitution  {{ date: '2023-05-15T00:00Z', id: '2023-05-15-product-constitution' }}

The opportunity opened by Large Language Models (LLMs) is vast. It’s allowed the birth of Dust, an AI-native company that wants to make work “work better” for smart teams. Deciding on a product constitution to guide what Dust would focus on in the vast space of possible directions was important to us. It will will help us decide locally more effectively. We look forward to continuously improving this first version we’re sharing here.

![](@/media/2023-05-15-product-constitution/img.png)

### Lessons from lives past

Most of our early careers were spent in smaller teams, including our own at a company Stan and I founded in 2011. 

With a few motivated humans around a table, very little is required for things to “work”. Informal processes and decisions were often enough, and many different forms of artisanal collaboration were valid options. you just got it done, and if anything needed adjusting, you adjusted there and then. 

We’d heard that things got significantly worse as teams got bigger. That said, with experiences at companies like Stripe or Alan, we’d been fortunate enough to see that some companies make a deliberate effort to challenge some of the seemingly inevitable decay in collaboration that teams experience as they grow.

There seemed to be ways to make things “work better”, but it wasn’t clear what. A strong culture? Enshrined [operating principles](https://stripe.com/gb/jobs/culture) that you [cover how to work and what to work on](https://alan.com/about/company-culture/a/leadership-principles)? Many team members that had themselves been founders? Dependency on [transparent, written communication](https://stripe.com/blog/scaling-email-transparency)? All of the above?

Great companies seem to be places where great people feel excited to do great work. Could those initial conditions be productised? 

### A new world of opportunity

Excited by the idea of making work “work better” for teams, various early prototypes explored how members of a team could be encouraged to collaborate in a way that help information flow more effectively and better decisions get made faster. 

That said, in 2020 and 2021 nothing really clicked enough. It wasn’t clear what would be the “10x better” in these prototypes. Software that strongly encourages or frankly coerces users into one behaviour or another seemed like it was repeating the patterns of software solutions of the past, simply with *our* preferences baked in instead of others’.

The emergence of Large Language Models (LLMs) over the past years really opened up a work of opportunity in that regard. For what seemed to be the first time: 

- **Plain English became a programming language**, meaning than most humans would eventually be able to ask software to act exactly as they wanted it to regardless of technical ability;
- **“Write” and “Read” could be separated**. How information was *contributed by an author* could be processed and adapted before being *consumed by a reader**;***
- **Software could take a shot at more complex and poorly defined tasks.** The emergence of agents with multimodal interaction capabilities opened the doors of more boring tasks being taken on by machines, and more time for humans to focus on what they got up in the morning to do.

LLMs looked like the disruption we’d been hoping for.

Early in 2022, it seemed that LLMs were moving from a “research mostly” to a “product mostly” problem space, with the development of novel interfaces and experiences at stake. What’s more, the “bigger is better” paradigm of LLMs that still holds today made it less clear what the advantage of re-developing models from scratch would be in the short term. Thus, as an AI-native company and with a profound desire to innovate in the application layer to make work “work better”, Dust was born. 

The technology at the heart of this disruption, like any powerful technology, could be wielded in a dizzying number of directions, some more desirable than others to us. Some of the questions that we were asking ourselves or that we were getting asked by our community shed a harsh light on these directions: 

- Would AI be used to replace humans?
- Could anything enduringly valuable still be built, if a few very large companies built the largest models? How would differentiation play out among companies deciding to focus on the “application layer” above foundation models?
- Would AI be an advantage for new companies or incumbents’ products? After all, the mobile era gave us a more powerful Salesforce, not a mobile replacement to Salesforce.
- What was the deal with hallucinations, anyway? Were they just part of the cost of doing business in this brave new world?
- Should we build tools for ML engineers? For software developers? For anyone?

“To chose is to renounce”, as André Gide elegantly phrased, and we needed to clarify, for ourselves, our users, and anyone deciding to join our team, which directions to explore on Dust’s long road ahead.

And so, we wrote the first version of Dust’s Product Constitution.

### Product Constitution (as of May 2023)

Dust choses the following to guide product decisions:

**Augmenting humans, not replacing them.** We're optimistic about making work life better for smart people. We're building R2-D2, not Terminator.

**Focusing on the upside.** There's so much machines can help with, and we'd rather focus on increasing the upside rather than cutting costs.

**Investing in craftsmanship over chatbots, hard problems over hype.** There's a little more to great products and experiences than wrapping GPT-4 API calls into a chat UI. We're in this to solve hard problems at hand on user experience and product quality.

**Building with an AI core.** Being an LLM-native company, we're building with large language models in mind from the ground up, rather than sprinkling them here and there.

**Being Safe and Sound.** Your data's sensitive, and you can't just accept “making things up” as a standard. Our North Star lies between Factualness, Safety, and Security. We aspire to define standards in this respect rather than simply abide by the existing ones.

**Focusing on tinkerers, striving to be useful to everyone.** We make tools with the makers in mind. Those who want to bend software to their will deserve a way to do it and are our core audience, and not all are developers. We'll work hard to make users happy with or without technical know-how.

### A work in perpetual progress

As we continue to discovery and engineer new and meaningful ways for teams to get better work done together, we fully expect to also iterate on the Constitution above. After all, what’s a good Constitution if it can’t handle a few amendments? 

We look forward to sharing more with you as we grow, learn, and build!
import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

![](@/media/2023-06-02-speculative-sampling/example.gif)

## Speculative sampling: how LLMs can write a lot faster using other LLMs {{ date: '2023-06-02T00:00Z', id: '2023-06-02-speculative-sampling' }}

Behind the beautiful name of _Speculative sampling_ lies a neat technique to have a large language model can generate tokens **up to three times faster** ðŸ”¥ The technique has been developed by various research teams, including one from Google DeepMind [who published it here](https://arxiv.org/pdf/2302.01318.pdf).

---

![](@/media/configuration-files.png)

## Fake post 2: Project configuration files {{ date: '2023-03-17T00:00Z', id: '2023-03-17-fake-post-2' }}

I've added support for creating per-project `.commitrc` files that override your global settings for that particular project. Went with YAML for these because personally I'm sick of quoting keys in JSON all the time, or accidentally leaving in a trailing comma.

---

![](@/media/dark-mode.png)

## Fake post 1: Dark mode support {{ date: '2023-03-06T00:00Z', id: '2023-03-06-fake-post-1' }}

I released this thing last week hoping a couple of people would say "awesome job" and make me feel good about what I'd built but instead I just got a ton of people shaming me on Twitter for being such a horrible person for only shipping a light UI.
